- type: Schedule
  members:
    - speaker: Mangpo Phothilimthana (Google)
      date: M 10/09/23
      title: "ML for ML Compilers"
      livestream: https://www.youtube.com/watch?v=VASg2XNgj-4
      abstract: "Search-based techniques have been demonstrated effective in solving complex optimization problems that arise in domain-specific compilers for machine learning (ML). Unfortunately, deploying such techniques in production compilers is impeded by several limitations. In this talk, I will present an autotuner for production ML compilers that can tune both graph-level and subgraph-level optimizations at multiple compilation stages. We demonstrate how to incorporate machine learning techniques such as a learned cost model and various learning-based search strategies to reduce autotuning time. Our learned cost model has high accuracy and outperforms a heavily-optimized analytical performance model. In an evaluation across 150 ML training and inference models on Tensor Processing Units (TPUs), the autotuner offers up to 2.4x and an average 5% runtime speedup over the heavily-optimized XLA compiler. I will outline how we deploy the learning-based XLA autotuner at datacenter scale to automatically tune the most heavily-used production models in Google's fleet everyday. The deployed tile size autotuner has been saving approximately 2% of fleetwide TPU compute time. We recently released a public dataset (https://github.com/google-research-datasets/tpu_graphs) for the learned cost model, and host an on-going Kaggle competition on the dataset (https://www.kaggle.com/competitions/predict-ai-model-runtime) to promote more research in ML for Systems."
      bio: "Phitchaya Mangpo Phothilimthana is a Staff research scientist at Google DeepMind (previously Google Brain), where she leads Machine Learning for Machine Learning Compilers effort (one of Google Brain moonshots in 2020). Her research interests include compilers, machine learning for systems, program synthesis, and energy-aware computing. Mangpo received an undergraduate degree in Computer Science from MIT and PhD from UC Berkeley. Mangpo was a recipient of Microsoft Research PhD Fellowship and Qualcomm Innovation Fellowship."
    - speaker: Martin Maas (Google)
      date: M 10/16/23
      title: "A Taxonomy of Machine Learning for Systems Problems"
      abstract: "Machine learning has the potential to significantly improve computer systems. While recent research in this area has shown great promise, not all problems are equally well-suited for applying ML techniques, and some remaining challenges have prevented wider adoption of ML in systems. In this talk, I will introduce a taxonomy to classify machine learning for systems approaches, discuss how to identify cases that are a good fit for machine learning, and lay out a longer-term vision of how different systems can be improved using ML techniques, ranging from computer architecture to language runtimes."
      bio: "Martin Maas is a Staff Research Scientist at Google DeepMind. His research interests are in language runtimes, computer architecture, systems, and machine learning, with a focus on applying machine learning to systems problems. Before joining Google, Martin completed his PhD in Computer Science at the University of California at Berkeley, where he worked on hardware support for managed languages and architectural support for memory-trace obliviousness."
      livestream: https://www.youtube.com/watch?v=4_UdAR_5jqk
    - speaker: Tim Dettmers (UW)
      date: M 10/23/23
    - speaker: Deepak Narayanan (Nvidia)
      date: M 10/30/23
    - speaker: Ce Zhang (Together, U Chicago)
      date: M 11/06/23
    - speaker: William Fedus (OpenAI)
      date: M 11/13/23
    - speaker: Thanksgiving
    - speaker: Tianqi Chen (CMU)
      date: M 11/27/23
    - speaker: Dan Fu (Stanford, Together)
      date: M 12/04/23